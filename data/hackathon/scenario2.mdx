---
title: Enabling GPU accelerators
exercise: 2
date: '2024-06-06'
tags: ['openshift','ai','kubernetes']
draft: false
authors: ['default']
summary: "How do we use GPU accelerators??"
---

As a sales team you've got an upcoming call with the ACME Financial Services Principal Data Scientist Peter Norvig, who has asked you to show them how to enable GPU support on their cloud cluster and started going off the deep end about how complex it was.

They had apparently already managed to add a gpu machine pool, but are now lost with all the operator mumbo jumbo that you're supposed to do after that to get GPU's running in Kubernetes.

You've agreed to show them how it's done and are joining the MicroSoft Skype for Businessâ„¢ call in 5 minutes. Can you win back the support of Peter and keep the deal on track? Time to shine ðŸ˜…

<Zoom>
|![training](/hackathon/static/images/hackathon/training.jpg)                   |
|:-----------------------------------------------------------------------------:|
| *Apparently gpu's are expensive??*                                            |
</Zoom>

## 2.1 - View cluster machine pool

You start off the call by double checking what Peter has already done just to make sure the GPU `MachinePool` looks ok.

Navigating to `Compute` > `MachineSets` in the OpenShift cluster you take a note of the GPU enabled machine set that is present and the number of replicas.

## 2.2 - Install required operators

With the GPU machine provisioned, you then walk Peter through how to install the two **required** operators:

- Node Feature Discovery
- Nvidia GPU Operator

With the operators installed you also step through creating the required **NodeFeatureDiscovery** and **ClusterPolicy** custom resources.

Documentation you may find helpful is:

- https://cloud.redhat.com/experts/rosa/gpu

## 2.3 - Confirm the gpu model

That's it, you nailed it! Peter is impressed with how quickly and clearly you stepped him through the process at short notice and is back on side ðŸŽ‰

One final question did pop up though. Peter couldn't remember which model of GPU came with his earlier created machine and wanted to double check that from within the OpenShift console, he also wanted to see some key details like GPU memory along with CUDA and driver versions.

You remember the super helpful `nvidia-smi` cli utility which quickly prints all that summary information and run that for Peter to answer his questions. Job done!

## 2.4 - Check your work

If you have won Peter back on side take a screenshot of the output from `nvidia-smi` (make sure it includes your pod name) and post a message in `#event-anz-ocp-ai-hackathon` with the screenshot and message:

> Please review [team name] solution for exercise 2.

This exercise is worth `750k`. If you engage the services of the contractor (by obtaining a hint from the hackathon moderators), it will cost you `25k`, which will be deducted from the respective challenge's deal value to your team.
The event team will reply in slack to confirm your updated team total deal size.
